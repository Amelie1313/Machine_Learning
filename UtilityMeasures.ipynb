{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_entropy(df, quasi_identifiers):\n",
    "    eq_class_counts = df.groupby(quasi_identifiers).size()\n",
    "    total_records = len(df)\n",
    "    probabilities = eq_class_counts / total_records\n",
    "    entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "    return entropy\n",
    "\n",
    "def calculate_granularity(df, quasi_identifiers):\n",
    "    eq_class_counts = df.groupby(quasi_identifiers).size()\n",
    "    total_records = len(df)\n",
    "    granularity = total_records / len(eq_class_counts)\n",
    "    return granularity\n",
    "\n",
    "\"\"\"\n",
    "Number of records changed\n",
    "Another useful statistic is the number of records changed per variable. These can be counted in a similar way as the missing values and include suppressions (i.e., changes to missing/’NA’ in R). \n",
    "The number of records changed gives a good indication of the impact of the anonymization methods on the data. Listing 41 illustrates how to compute the number of records changed for the PRAMmed variables.\n",
    "https://sdcpractice.readthedocs.io/en/latest/utility.html \n",
    "\"\"\"\n",
    "def information_loss(original_df, anonymized_df, quasi_identifiers):\n",
    "    changes = (original_df[quasi_identifiers] != anonymized_df[quasi_identifiers]).sum().sum()\n",
    "    total_values = original_df[quasi_identifiers].size\n",
    "    return changes / total_values\n",
    "\n",
    "\"\"\"\n",
    "IL1s information loss measure: only for continous variables\n",
    "https://sdcpractice.readthedocs.io/en/latest/utility.html \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_IL1s(original_df, anonymized_df, continuous_columns):\n",
    "    n = len(original_df)  # Number of records\n",
    "    p = len(continuous_columns)  # Number of continuous variables\n",
    "\n",
    "    total_loss = 0\n",
    "    for col in continuous_columns:\n",
    "        std_dev = original_df[col].std()  \n",
    "        if std_dev == 0:\n",
    "            print(\"Warning: std_dev is zero\")  \n",
    "\n",
    "        # Sum of absolute differences between original and anonymized values\n",
    "        col_loss = np.sum(np.abs(original_df[col] - anonymized_df[col])) / np.sqrt(2 * std_dev)\n",
    "        total_loss += col_loss\n",
    "\n",
    "    return (1 / (p * n)) * total_loss if p * n > 0 else 0  \n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Example: I don't have the anonymized data yet, but this is how it should work for entropy and granularity (I think, I havn't tested it yet)\n",
    "\n",
    "quasi_identifiers = ['QI1', 'QI2', 'QI3']  # Adjust based on your dataset\n",
    "\n",
    "# I'm not sure if we need the calculations for the original dataset (maybe for comparison)\n",
    "original_entropy = calculate_entropy(original_df, quasi_identifiers)\n",
    "original_granularity = calculate_granularity(original_df, quasi_identifiers)\n",
    "\n",
    "# For anonymized dataset\n",
    "anonymized_entropy = calculate_entropy(anonymized_df, quasi_identifiers)\n",
    "anonymized_granularity = calculate_granularity(anonymized_df, quasi_identifiers)\n",
    "\n",
    "# Print results\n",
    "print(f\"Original Entropy: {original_entropy:.4f}\")\n",
    "print(f\"Anonymized Entropy: {anonymized_entropy:.4f}\")\n",
    "print(f\"Increase in Entropy: {anonymized_entropy - original_entropy:.4f}\\n\")\n",
    "\n",
    "print(f\"Original Granularity: {original_granularity:.4f}\")\n",
    "print(f\"Anonymized Granularity: {anonymized_granularity:.4f}\")\n",
    "print(f\"Decrease in Granularity: {original_granularity - anonymized_granularity:.4f}\")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
